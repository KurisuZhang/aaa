Processor: Intel(R) Xeon(R) CPU @ 2.30GHz
RAM: 124Gi
GPU:     Product Name                          : Tesla V100-SXM2-16GB
    Product Name                          : Tesla V100-SXM2-16GB
    Product Name                          : Tesla V100-SXM2-16GB
    Product Name                          : Tesla V100-SXM2-16GB
Files already downloaded and verified

Running with 1 GPUs
Files already downloaded and verified
Epoch 2: Loss 0.9988
Batch size: 32, Training time for epoch: 38.81 seconds
Batch size: 32, Communication time for epoch: 7.9885 seconds

Running with 2 GPUs
Files already downloaded and verified
Epoch 2: Loss 0.9417
Batch size: 32, Training time for epoch: 20.18 seconds
Batch size: 32, Communication time for epoch: 3.9429 seconds
Files already downloaded and verified
Epoch 2: Loss 0.9290
Batch size: 32, Training time for epoch: 20.18 seconds
Batch size: 32, Communication time for epoch: 3.9822 seconds

Running with 4 GPUs
Files already downloaded and verified
Epoch 2: Loss 0.9683
Batch size: 32, Training time for epoch: 10.78 seconds
Batch size: 32, Communication time for epoch: 2.0244 seconds
Files already downloaded and verified
Epoch 2: Loss 0.9562
Batch size: 32, Training time for epoch: 10.78 seconds
Batch size: 32, Communication time for epoch: 2.0060 seconds
Files already downloaded and verified
Epoch 2: Loss 0.9697
Batch size: 32, Training time for epoch: 10.78 seconds
Batch size: 32, Communication time for epoch: 2.0630 seconds
Files already downloaded and verified
Epoch 2: Loss 0.9452
Batch size: 32, Training time for epoch: 10.78 seconds
Batch size: 32, Communication time for epoch: 2.0047 seconds

Running with 1 GPUs
Files already downloaded and verified
Epoch 2: Loss 0.9362
Batch size: 128, Training time for epoch: 34.08 seconds
Batch size: 128, Communication time for epoch: 2.0325 seconds

Running with 2 GPUs
Files already downloaded and verified
Epoch 2: Loss 0.9946
Batch size: 128, Training time for epoch: 17.70 seconds
Batch size: 128, Communication time for epoch: 1.0665 seconds
Files already downloaded and verified
Epoch 2: Loss 1.0184
Batch size: 128, Training time for epoch: 17.70 seconds
Batch size: 128, Communication time for epoch: 1.0830 seconds

Running with 4 GPUs
Files already downloaded and verified
Epoch 2: Loss 1.1239
Batch size: 128, Training time for epoch: 9.11 seconds
Batch size: 128, Communication time for epoch: 0.5382 seconds
Files already downloaded and verified
Epoch 2: Loss 1.1260
Batch size: 128, Training time for epoch: 9.11 seconds
Batch size: 128, Communication time for epoch: 0.5522 seconds
Files already downloaded and verified
Epoch 2: Loss 1.0901
Batch size: 128, Training time for epoch: 9.11 seconds
Batch size: 128, Communication time for epoch: 0.5435 seconds
Files already downloaded and verified
Epoch 2: Loss 1.1198
Batch size: 128, Training time for epoch: 9.11 seconds
Batch size: 128, Communication time for epoch: 0.5444 seconds

Running with 1 GPUs
Files already downloaded and verified
Epoch 2: Loss 1.0979
Batch size: 512, Training time for epoch: 31.92 seconds
Batch size: 512, Communication time for epoch: 0.5798 seconds

Running with 2 GPUs
Files already downloaded and verified
Epoch 2: Loss 1.3086
Batch size: 512, Training time for epoch: 16.52 seconds
Batch size: 512, Communication time for epoch: 0.3014 seconds
Files already downloaded and verified
Epoch 2: Loss 1.2940
Batch size: 512, Training time for epoch: 16.52 seconds
Batch size: 512, Communication time for epoch: 0.2971 seconds

Running with 4 GPUs
Files already downloaded and verified
Epoch 2: Loss 1.4656
Batch size: 512, Training time for epoch: 8.29 seconds
Batch size: 512, Communication time for epoch: 0.1514 seconds
Files already downloaded and verified
Epoch 2: Loss 1.4873
Batch size: 512, Training time for epoch: 8.29 seconds
Batch size: 512, Communication time for epoch: 0.1494 seconds
Files already downloaded and verified
Epoch 2: Loss 1.4977
Batch size: 512, Training time for epoch: 8.29 seconds
Batch size: 512, Communication time for epoch: 0.1443 seconds
Files already downloaded and verified
Epoch 2: Loss 1.4891
Batch size: 512, Training time for epoch: 8.29 seconds
Batch size: 512, Communication time for epoch: 0.1452 seconds
